{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모델을 우선적으로 호출합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) manual seed를 고정시킵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24af6a3fd50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) hyper parameter를 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) train, test set을 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=False)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) train set을 batch size를 지정하여 data loader에 넣어줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) CNN architecture를 구성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*64, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 생성된 모델의 architecture 출력 및 테스트를 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "value = torch.FloatTensor(1, 1, 28, 28)\n",
    "\n",
    "print(model(value).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) 모델 학습 전 loss function과 optimizer를 선언합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) model training을 시작합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:  1/15] loss: 0.2195\n",
      "[epoch:  2/15] loss: 0.0595\n",
      "[epoch:  3/15] loss: 0.0431\n",
      "[epoch:  4/15] loss: 0.0350\n",
      "[epoch:  5/15] loss: 0.0292\n",
      "[epoch:  6/15] loss: 0.0241\n",
      "[epoch:  7/15] loss: 0.0205\n",
      "[epoch:  8/15] loss: 0.0176\n",
      "[epoch:  9/15] loss: 0.0148\n",
      "[epoch: 10/15] loss: 0.0126\n",
      "[epoch: 11/15] loss: 0.0111\n",
      "[epoch: 12/15] loss: 0.0089\n",
      "[epoch: 13/15] loss: 0.0079\n",
      "[epoch: 14/15] loss: 0.0065\n",
      "[epoch: 15/15] loss: 0.0060\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for x_train, y_train in data_loader:\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "        \n",
    "    print('[epoch: {:2d}/{}] loss: {:.4f}'.format(epoch, epochs, avg_loss))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) test set을 이용하여 trained model을 테스트 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9890000224113464\n",
      "Label:  2\n",
      "Prediction:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN0ElEQVR4nO3dbaic9ZnH8d/P2EK0KmZzlGCTPW7JC2V9aBmSBUPNUrZEQaIvqvWFTwgpmpgWAq50IRVf+LBsWpcoQtTQ7NKNVGwwL6Qb0YIoUjIRE+OG3Wg4sWlickJexMaHmvTaF+d29ySe+c9x5p6H5Pp+YJiZ+5r7/C8m55d7zvxn7r8jQgDOfGcNugEA/UHYgSQIO5AEYQeSIOxAEmf3c7DZs2fH6OhoP4cEUhkbG9Phw4c9Va2rsNteIulfJc2Q9ExEPFp6/OjoqJrNZjdDAihoNBotax2/jLc9Q9KTkq6TdLmkW21f3unPA9Bb3fzNvkDSexGxJyL+LOk5SUvraQtA3boJ+yWS/jDp/r5q20lsL7PdtN0cHx/vYjgA3egm7FO9CfClz95GxLqIaEREY2RkpIvhAHSjm7DvkzR30v1vStrfXTsAeqWbsG+VNN/2pba/LumHkjbX0xaAunU89RYRx22vkPSfmph6Wx8R79bWGYBadTXPHhEvSXqppl4A9BAflwWSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm+nkoa/Xf//fcX61u2bCnWS2crlaSrrrqqWF+6tPVpCefNm1fcF/XiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTjiS4u49Eyj0QhWce2vHTt2FOuLFi0q1o8dO1ast/v9Oeus1seTW265pbjv008/Xayfc845xXpGjUZDzWZzyiWbObIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJ8n/0Md+WVVxbrR48eLda3b99erD///PPF+qZNm1rWNm7cWNz39ddfL9b37t1brONkXYXd9pikjySdkHQ8IspnOgAwMHUc2f8+Ig7X8HMA9BB/swNJdBv2kLTF9jbby6Z6gO1ltpu2m+Pj410OB6BT3Yb9moj4jqTrJC23/d1THxAR6yKiERGNkZGRLocD0Kmuwh4R+6vrQ5I2SVpQR1MA6tdx2G2fa/u8L25L+r6knXU1BqBe3bwbf7GkTba/+Dn/ERG/raUrDI1254VvV7/sssta1m677bbivvv37y/W230GoF1v2XQc9ojYI4lnEzhNMPUGJEHYgSQIO5AEYQeSIOxAEnzFFT21Z8+ejvc9ceJEsb527dpi/Zlnnul47DMRR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ5dnTlww8/LNaffPLJno29cOHCnv3sMxFHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignl2FB05cqRYv+eee4r1Q4cOdTz2zJkzi/UlS5Z0/LMz4sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwz57c8ePHi/UbbrihWH/zzTfrbOck9957b7E+d+7cno19Jmp7ZLe93vYh2zsnbZtl+2Xbu6vrC3vbJoBuTedl/C8lnfpRpQckvRIR8yW9Ut0HMMTahj0iXpN06mcml0raUN3eIOnGmvsCULNO36C7OCIOSFJ1fVGrB9peZrtpuzk+Pt7hcAC61fN34yNiXUQ0IqIxMjLS6+EAtNBp2A/aniNJ1XXnX20C0Bedhn2zpDuq23dIerGedgD0Stt5dtsbJS2WNNv2Pkk/k/SopF/bvlvSB5J+0Msm0TurVq0q1ns5j75y5cpi/ZFHHunZ2Bm1DXtE3Nqi9L2aewHQQ3xcFkiCsANJEHYgCcIOJEHYgST4iusZoPQ11XXr1hX3feKJJ+pu5yQ333xzy9rq1auL+559Nr+edeLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMJF5GoiIYr3ZbLasrVixou52TjJv3rxi/fHHH29ZmzVrVt3toIAjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTz7EGi3bHK70z2vXbu2znZOcu211xbrL7zwQrHOXPrw4MgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzz4ENmzYUKz3ch59dHS0WN+8eXOxft5559XYDXqp7ZHd9nrbh2zvnLTtQdt/tP12dbm+t20C6NZ0Xsb/UtKSKbb/IiKuri4v1dsWgLq1DXtEvCbpSB96AdBD3bxBt8L2jupl/oWtHmR7me2m7eb4+HgXwwHoRqdhf0rStyRdLemApDWtHhgR6yKiERGNkZGRDocD0K2Owh4RByPiRET8RdLTkhbU2xaAunUUdttzJt29SdLOVo8FMBzazrPb3ihpsaTZtvdJ+pmkxbavlhSSxiT9qIc9nvZK53WXpPvuu69nY7c7r/vWrVuLdebRzxxtwx4Rt06x+dke9AKgh/i4LJAEYQeSIOxAEoQdSIKwA0nwFdcaHD58uFhfvHhxsf7pp592Nf7ChQtb1l599dXivjNnzuxq7GFW+nd5//33i/uWntPTFUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCefZp2rZtW8tau2WNP/74467Gbvc11dLpnk/nefR2S1m3Wy769ttvb1l77LHHivsyzw7gtEXYgSQIO5AEYQeSIOxAEoQdSIKwA0kwz175/PPPi/VFixa1rLX7PrrtYv3SSy8t1p977rlifZAr7Rw7dqxY/+yzz1rW2p0HYMmSqdYT/X9jY2PF+vz581vW7rrrruK+ZyKO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPPslRkzZhTrq1atall7+OGHuxr77LPL/wy7du0q1j/55JOWtXbfhf/ggw+K9e3btxfr7b4Xvn///mK9G6Ojo8X6G2+80bJ2wQUX1NzN8Gt7ZLc91/bvbO+y/a7tH1fbZ9l+2fbu6vrC3rcLoFPTeRl/XNKqiLhM0t9JWm77ckkPSHolIuZLeqW6D2BItQ17RByIiLeq2x9J2iXpEklLJW2oHrZB0o29ahJA977SG3S2RyV9W9LvJV0cEQekif8QJF3UYp9ltpu2m+Pj4911C6Bj0w677W9IekHSTyLi6HT3i4h1EdGIiMYgv7ABZDetsNv+miaC/quI+E21+aDtOVV9jqRDvWkRQB3aTr154vuZz0raFRE/n1TaLOkOSY9W1y/2pMM+Oeus8v97Dz30UMtau9M1r1mzpljfvXt3sX7nnXcW6yXtphRPnDjR8c/u1vnnn1+sr1y5slhfvXp1sd5uSjOb6Twb10i6TdI7tt+utv1UEyH/te27JX0g6Qe9aRFAHdqGPSJel9Tq7Avfq7cdAL3Cx2WBJAg7kARhB5Ig7EAShB1IwhHRt8EajUY0m82+jTcs2p0y+amnnirW169fX6zv3bv3K/dUl5tuuqlYv+KKK1rWli9fXtyXT1x+dY1GQ81mc8rZM47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE8+zAGYR5dgCEHciCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETbsNuea/t3tnfZftf2j6vtD9r+o+23q8v1vW8XQKemsz77cUmrIuIt2+dJ2mb75ar2i4j4l961B6Au01mf/YCkA9Xtj2zvknRJrxsDUK+v9De77VFJ35b0+2rTCts7bK+3fWGLfZbZbtpujo+Pd9UsgM5NO+y2vyHpBUk/iYijkp6S9C1JV2viyL9mqv0iYl1ENCKiwdpdwOBMK+y2v6aJoP8qIn4jSRFxMCJORMRfJD0taUHv2gTQrem8G29Jz0raFRE/n7R9zqSH3SRpZ/3tAajLdN6Nv0bSbZLesf12te2nkm61fbWkkDQm6Uc96RBALabzbvzrkqY6D/VL9bcDoFf4BB2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T/BrPHJe2dtGm2pMN9a+CrGdbehrUvid46VWdvfx0RU57/ra9h/9LgdjMiGgNroGBYexvWviR661S/euNlPJAEYQeSGHTY1w14/JJh7W1Y+5LorVN96W2gf7MD6J9BH9kB9AlhB5IYSNhtL7H937bfs/3AIHpoxfaY7XeqZaibA+5lve1DtndO2jbL9su2d1fXU66xN6DehmIZ78Iy4wN97ga9/Hnf/2a3PUPS/0j6B0n7JG2VdGtE/FdfG2nB9pikRkQM/AMYtr8r6U+S/i0i/rba9s+SjkTEo9V/lBdGxD8OSW8PSvrToJfxrlYrmjN5mXFJN0q6UwN87gp93aw+PG+DOLIvkPReROyJiD9Lek7S0gH0MfQi4jVJR07ZvFTShur2Bk38svRdi96GQkQciIi3qtsfSfpimfGBPneFvvpiEGG/RNIfJt3fp+Fa7z0kbbG9zfayQTczhYsj4oA08csj6aIB93Oqtst499Mpy4wPzXPXyfLn3RpE2KdaSmqY5v+uiYjvSLpO0vLq5SqmZ1rLePfLFMuMD4VOlz/v1iDCvk/S3En3vylp/wD6mFJE7K+uD0napOFbivrgFyvoVteHBtzP/xmmZbynWmZcQ/DcDXL580GEfauk+bYvtf11ST+UtHkAfXyJ7XOrN05k+1xJ39fwLUW9WdId1e07JL04wF5OMizLeLdaZlwDfu4Gvvx5RPT9Iul6Tbwj/76kfxpEDy36+htJ26vLu4PuTdJGTbys+1wTr4julvRXkl6RtLu6njVEvf27pHck7dBEsOYMqLdFmvjTcIekt6vL9YN+7gp99eV54+OyQBJ8gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvhfs+U92spDaUQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print('accuracy: ', accuracy.item())\n",
    "    \n",
    "    r = random.randint(1, len(mnist_test)-1)\n",
    "    x_test_random = mnist_test.test_data[r].view(-1, 1, 28, 28).float()\n",
    "    y_test_random = mnist_test.test_labels[r]\n",
    "    prediction_random = model(x_test_random)\n",
    "    \n",
    "    print('Label: ', y_test_random.item())\n",
    "    print('Prediction: ', torch.argmax(prediction_random, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r].view(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/15 >>> loss: 0.219523\n",
      "epoch:  2/15 >>> loss: 0.059500\n",
      "epoch:  3/15 >>> loss: 0.043120\n",
      "epoch:  4/15 >>> loss: 0.034964\n",
      "epoch:  5/15 >>> loss: 0.029212\n",
      "epoch:  6/15 >>> loss: 0.024081\n",
      "epoch:  7/15 >>> loss: 0.020534\n",
      "epoch:  8/15 >>> loss: 0.017575\n",
      "epoch:  9/15 >>> loss: 0.014786\n",
      "epoch: 10/15 >>> loss: 0.012596\n",
      "epoch: 11/15 >>> loss: 0.011091\n",
      "epoch: 12/15 >>> loss: 0.008926\n",
      "epoch: 13/15 >>> loss: 0.007890\n",
      "epoch: 14/15 >>> loss: 0.006487\n",
      "epoch: 15/15 >>> loss: 0.006021\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=False)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=False)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*64, 10, bias=True)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = CNN()\n",
    "# value = torch.FloatTensor(1, 1, 28, 28)\n",
    "# model(value).shape\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for x_train, y_train in data_loader:        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "    \n",
    "    print('epoch: {:2d}/{} >>> loss: {:.6f}'.format(epoch, epochs, avg_loss))    \n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9890000224113464\n",
      "Label:  4\n",
      "Prediction:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    x_test = mnist_test.test_data.view(len(mnist_test), -1, 28, 28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print('accuracy: ', accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    x_test_r = x_test[r].view(-1, 1, 28, 28)\n",
    "    y_test_r = y_test[r]\n",
    "    prediction_r = model(x_test_r)\n",
    "    \n",
    "    print('Label: ', y_test_r.item())\n",
    "    print('Prediction: ', torch.argmax(prediction_r, 1).item())\n",
    "    \n",
    "    plt.imshow(x_test_r.view(28, 28), cmap='Greys')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
