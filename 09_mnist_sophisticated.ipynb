{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (sophisticated version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모듈을 호출해옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 재현성을 위해 manual seed를 고정시킵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 학습모델에 필요한 parameter를 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "drop_prob = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 학습, 테스트셋을 불러옵니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) minibatch 학습을 위해 학습셋을 data loader에 담아둡니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 순차적으로 구성합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1) layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(28*28, 512, bias=True)\n",
    "linear2 = nn.Linear(512, 512, bias=True)\n",
    "linear3 = nn.Linear(512, 512, bias=True)\n",
    "linear4 = nn.Linear(512, 512, bias=True)\n",
    "linear5 = nn.Linear(512, 10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2) batch normalization 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm1d(512)\n",
    "bn2 = nn.BatchNorm1d(512)\n",
    "bn3 = nn.BatchNorm1d(512)\n",
    "bn4 = nn.BatchNorm1d(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3) activation function 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4) drop out 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5) xavier initialization 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0062,  0.0919,  0.0401,  ...,  0.0947,  0.0152,  0.0836],\n",
       "        [-0.1033,  0.0740, -0.1042,  ..., -0.0101, -0.1031,  0.0913],\n",
       "        [ 0.0159,  0.0725, -0.0175,  ...,  0.0040, -0.0089,  0.0846],\n",
       "        ...,\n",
       "        [ 0.0346, -0.0231, -0.0486,  ..., -0.0093,  0.0555, -0.0069],\n",
       "        [ 0.0428,  0.0078,  0.1065,  ...,  0.0770, -0.0763, -0.0529],\n",
       "        [ 0.0188,  0.1003,  0.0487,  ..., -0.0199,  0.0350,  0.0018]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(linear1.weight)\n",
    "nn.init.xavier_uniform_(linear2.weight)\n",
    "nn.init.xavier_uniform_(linear3.weight)\n",
    "nn.init.xavier_uniform_(linear4.weight)\n",
    "nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-6) model 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                     linear2, bn2, relu, dropout,\n",
    "                     linear3, bn3, relu, dropout,\n",
    "                     linear4, bn4, relu, dropout,\n",
    "                     linear5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습 전 loss function과 optimizer를 지정해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) for문을 돌면서 training을 시작합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     1/15 >>> loss: 2.040840\n",
      "epoch:     2/15 >>> loss: 1.189549\n",
      "epoch:     3/15 >>> loss: 0.844580\n",
      "epoch:     4/15 >>> loss: 0.668496\n",
      "epoch:     5/15 >>> loss: 0.564478\n",
      "epoch:     6/15 >>> loss: 0.492442\n",
      "epoch:     7/15 >>> loss: 0.450266\n",
      "epoch:     8/15 >>> loss: 0.409527\n",
      "epoch:     9/15 >>> loss: 0.381354\n",
      "epoch:    10/15 >>> loss: 0.357957\n",
      "epoch:    11/15 >>> loss: 0.336629\n",
      "epoch:    12/15 >>> loss: 0.316045\n",
      "epoch:    13/15 >>> loss: 0.308771\n",
      "epoch:    14/15 >>> loss: 0.289843\n",
      "epoch:    15/15 >>> loss: 0.281586\n",
      "learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for x_train, y_train in data_loader:\n",
    "        x_train = x_train.view(-1, 28*28)\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "        \n",
    "    print('epoch: {:5d}/{} >>> loss: {:.6f}'.format(epoch, epochs, avg_loss.item()))\n",
    "    \n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) 학습된 모델을 평가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416999816894531\n",
      "Label:  1\n",
      "Prediction:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print(accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    x_random_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_random_data = mnist_test.test_labels[r:r+1]\n",
    "    \n",
    "    print('Label: ', y_random_data.item())\n",
    "    single_prediction = model(x_random_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
