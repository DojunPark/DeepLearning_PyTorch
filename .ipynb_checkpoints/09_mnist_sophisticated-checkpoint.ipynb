{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (sophisticated version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모듈을 호출해옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 재현성을 위해 manual seed를 고정시킵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 학습모델에 필요한 parameter를 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "drop_prob = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 학습, 테스트셋을 불러옵니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) minibatch 학습을 위해 학습셋을 data loader에 담아둡니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 순차적으로 구성합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1) layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(28*28, 512, bias=True)\n",
    "linear2 = nn.Linear(512, 512, bias=True)\n",
    "linear3 = nn.Linear(512, 512, bias=True)\n",
    "linear4 = nn.Linear(512, 512, bias=True)\n",
    "linear5 = nn.Linear(512, 10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2) batch normalization 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm1d(512)\n",
    "bn2 = nn.BatchNorm1d(512)\n",
    "bn3 = nn.BatchNorm1d(512)\n",
    "bn4 = nn.BatchNorm1d(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3) activation function 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4) drop out 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5) xavier initialization 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0062,  0.0919,  0.0401,  ...,  0.0947,  0.0152,  0.0836],\n",
       "        [-0.1033,  0.0740, -0.1042,  ..., -0.0101, -0.1031,  0.0913],\n",
       "        [ 0.0159,  0.0725, -0.0175,  ...,  0.0040, -0.0089,  0.0846],\n",
       "        ...,\n",
       "        [ 0.0346, -0.0231, -0.0486,  ..., -0.0093,  0.0555, -0.0069],\n",
       "        [ 0.0428,  0.0078,  0.1065,  ...,  0.0770, -0.0763, -0.0529],\n",
       "        [ 0.0188,  0.1003,  0.0487,  ..., -0.0199,  0.0350,  0.0018]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(linear1.weight)\n",
    "nn.init.xavier_uniform_(linear2.weight)\n",
    "nn.init.xavier_uniform_(linear3.weight)\n",
    "nn.init.xavier_uniform_(linear4.weight)\n",
    "nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-6) model 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                     linear2, bn2, relu, dropout,\n",
    "                     linear3, bn3, relu, dropout,\n",
    "                     linear4, bn4, relu, dropout,\n",
    "                     linear5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습 전 loss function과 optimizer를 지정해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) for문을 돌면서 training을 시작합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     1/15 >>> loss: 2.040840\n",
      "epoch:     2/15 >>> loss: 1.189549\n",
      "epoch:     3/15 >>> loss: 0.844580\n",
      "epoch:     4/15 >>> loss: 0.668496\n",
      "epoch:     5/15 >>> loss: 0.564478\n",
      "epoch:     6/15 >>> loss: 0.492442\n",
      "epoch:     7/15 >>> loss: 0.450266\n",
      "epoch:     8/15 >>> loss: 0.409527\n",
      "epoch:     9/15 >>> loss: 0.381354\n",
      "epoch:    10/15 >>> loss: 0.357957\n",
      "epoch:    11/15 >>> loss: 0.336629\n",
      "epoch:    12/15 >>> loss: 0.316045\n",
      "epoch:    13/15 >>> loss: 0.308771\n",
      "epoch:    14/15 >>> loss: 0.289843\n",
      "epoch:    15/15 >>> loss: 0.281586\n",
      "learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for x_train, y_train in data_loader:\n",
    "        x_train = x_train.view(-1, 28*28)\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "        \n",
    "    print('epoch: {:5d}/{} >>> loss: {:.6f}'.format(epoch, epochs, avg_loss.item()))\n",
    "    \n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) 학습된 모델을 평가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\Dojun Park\\AppData\\Local\\Continuum\\anaconda3\\envs\\python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416999816894531\n",
      "Label:  1\n",
      "Prediction:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print(accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    x_random_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float()\n",
    "    y_random_data = mnist_test.test_labels[r:r+1]\n",
    "    \n",
    "    print('Label: ', y_random_data.item())\n",
    "    single_prediction = model(x_random_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1/15 >>> loss: 1.384594\n",
      "epoch:  2/15 >>> loss: 0.955447\n",
      "epoch:  3/15 >>> loss: 0.639873\n",
      "epoch:  4/15 >>> loss: 0.514361\n",
      "epoch:  5/15 >>> loss: 0.604509\n",
      "epoch:  6/15 >>> loss: 0.502391\n",
      "epoch:  7/15 >>> loss: 0.376140\n",
      "epoch:  8/15 >>> loss: 0.324751\n",
      "epoch:  9/15 >>> loss: 0.618807\n",
      "epoch: 10/15 >>> loss: 0.395587\n",
      "epoch: 11/15 >>> loss: 0.167818\n",
      "epoch: 12/15 >>> loss: 0.358989\n",
      "epoch: 13/15 >>> loss: 0.260041\n",
      "epoch: 14/15 >>> loss: 0.145858\n",
      "epoch: 15/15 >>> loss: 0.299833\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 15\n",
    "learning_rate = 1e-5\n",
    "drop_prop = 0.3\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "\n",
    "linear1 = nn.Linear(28*28, 512, bias=True)\n",
    "linear2 = nn.Linear(512, 512, bias=True)\n",
    "linear3 = nn.Linear(512, 512, bias=True)\n",
    "linear4 = nn.Linear(512, 512, bias=True)\n",
    "linear5 = nn.Linear(512, 10, bias=True)\n",
    "\n",
    "bn1 = nn.BatchNorm1d(512)\n",
    "bn2 = nn.BatchNorm1d(512)\n",
    "bn3 = nn.BatchNorm1d(512)\n",
    "bn4 = nn.BatchNorm1d(512)\n",
    "\n",
    "relu = nn.ReLU()\n",
    "dropout = nn.Dropout(p=drop_prop)\n",
    "\n",
    "nn.init.xavier_uniform_(linear1.weight)\n",
    "nn.init.xavier_uniform_(linear2.weight)\n",
    "nn.init.xavier_uniform_(linear3.weight)\n",
    "nn.init.xavier_uniform_(linear4.weight)\n",
    "nn.init.xavier_uniform_(linear5.weight)\n",
    "\n",
    "model = nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                     linear2, bn2, relu, dropout,\n",
    "                     linear3, bn3, relu, dropout,\n",
    "                     linear4, bn4, relu, dropout,\n",
    "                     linear5)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for x_train, y_train in data_loader:\n",
    "        x_train = x_train.view(-1, 28*28).float()\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "    \n",
    "    print('epoch: {:2d}/{} >>> loss: {:.6f}'.format(epoch, epochs, loss.item()))\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9470000267028809\n",
      "label:  5\n",
      "prediction:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    x_test = mnist_test.test_data.view(-1, 28*28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print('accuracy: ', accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    x_test_random = x_test[r].view(-1, 28*28)\n",
    "    y_test_random = y_test[r]\n",
    "    prediction_random = model(x_test_random)\n",
    "    \n",
    "    print('label: ', y_test_random.item())\n",
    "    print('prediction: ', torch.argmax(prediction_random, 1).item())\n",
    "    \n",
    "    plt.imshow(x_test_random.view(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
