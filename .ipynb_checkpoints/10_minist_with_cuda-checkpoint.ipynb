{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (with cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 필요한 모듈을 호출해옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) device 지정 & manual seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 학습모델에 필요한 parameter를 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 15\n",
    "batch_size = 100\n",
    "drop_prob = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 학습, 테스트셋을 불러옵니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) minibatch 학습을 위해 학습셋을 data loader에 담아둡니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델을 순차적으로 구성합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1) layer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(28*28, 512, bias=True)\n",
    "linear2 = nn.Linear(512, 512, bias=True)\n",
    "linear3 = nn.Linear(512, 512, bias=True)\n",
    "linear4 = nn.Linear(512, 512, bias=True)\n",
    "linear5 = nn.Linear(512, 10, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2) batch normalization 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = nn.BatchNorm1d(512)\n",
    "bn2 = nn.BatchNorm1d(512)\n",
    "bn3 = nn.BatchNorm1d(512)\n",
    "bn4 = nn.BatchNorm1d(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3) activation function 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-4) drop out 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=drop_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-5) xavier initialization 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0147, -0.0003, -0.0210,  ...,  0.0707, -0.0314, -0.0136],\n",
       "        [ 0.0718, -0.0103,  0.0366,  ..., -0.0319,  0.0462,  0.0303],\n",
       "        [ 0.0575, -0.0890, -0.0492,  ...,  0.0100,  0.0807, -0.0359],\n",
       "        ...,\n",
       "        [-0.0403,  0.0531, -0.0981,  ...,  0.0617, -0.0011,  0.0624],\n",
       "        [-0.0896,  0.0671,  0.0815,  ...,  0.0659,  0.1023, -0.0633],\n",
       "        [ 0.1020,  0.0481, -0.0295,  ..., -0.1030, -0.0380, -0.0858]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(linear1.weight)\n",
    "nn.init.xavier_uniform_(linear2.weight)\n",
    "nn.init.xavier_uniform_(linear3.weight)\n",
    "nn.init.xavier_uniform_(linear4.weight)\n",
    "nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-6) model 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, bn1, relu, dropout,\n",
    "                     linear2, bn2, relu, dropout,\n",
    "                     linear3, bn3, relu, dropout,\n",
    "                     linear4, bn4, relu, dropout,\n",
    "                     linear5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습 전 loss function과 optimizer를 지정해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) for문을 돌면서 training을 시작합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = len(data_loader)\n",
    "model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for x_train, y_train in data_loader:\n",
    "        x_train = x_train.view(-1, 28*28).to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        \n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        loss = loss_function(prediction, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss / total_batch\n",
    "        \n",
    "    print('epoch: {:5d}/{} >>> loss: {:.6f}'.format(epoch, epochs, avg_loss.item()))\n",
    "    \n",
    "print('learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) 학습된 모델을 평가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(x_test)\n",
    "    correct = torch.argmax(prediction, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print(accuracy.item())\n",
    "    \n",
    "    r = random.randint(0, len(mnist_test)-1)\n",
    "    x_random_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float().to(device)\n",
    "    y_random_data = mnist_test.test_labels[r:r+1].to(device)\n",
    "    \n",
    "    print('Label: ', y_random_data.item())\n",
    "    single_prediction = model(x_random_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r+1].view(28,28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
